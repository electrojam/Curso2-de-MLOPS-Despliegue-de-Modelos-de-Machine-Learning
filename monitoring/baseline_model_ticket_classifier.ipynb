{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from joblib import load, dump\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/tickets_inputs_eng_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>ticket_classification</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>relevant_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18961</td>\n",
       "      <td>18961</td>\n",
       "      <td>18961</td>\n",
       "      <td>18961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18822</td>\n",
       "      <td>78</td>\n",
       "      <td>18714</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Chase has violated 15 USC 1692 by continuing c...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "      <td>chase continu collect activ report complet cre...</td>\n",
       "      <td>Mortgage/Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11</td>\n",
       "      <td>4918</td>\n",
       "      <td>12</td>\n",
       "      <td>16376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  complaint_what_happened  \\\n",
       "count                                               18961   \n",
       "unique                                              18822   \n",
       "top     Chase has violated 15 USC 1692 by continuing c...   \n",
       "freq                                                   11   \n",
       "\n",
       "                                    ticket_classification  \\\n",
       "count                                               18961   \n",
       "unique                                                 78   \n",
       "top     Credit card or prepaid card + General-purpose ...   \n",
       "freq                                                 4918   \n",
       "\n",
       "                                           processed_text relevant_topics  \n",
       "count                                               18961           18961  \n",
       "unique                                              18714               3  \n",
       "top     chase continu collect activ report complet cre...   Mortgage/Loan  \n",
       "freq                                                   12           16376  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>ticket_classification</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>relevant_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
       "      <td>Debt collection + Credit card debt</td>\n",
       "      <td>morn name appreci chase bank cardmemb servic c...</td>\n",
       "      <td>Mortgage/Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "      <td>card anniversari date inform order account ann...</td>\n",
       "      <td>Mortgage/Loan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             complaint_what_happened  \\\n",
       "0  Good morning my name is XXXX XXXX and I apprec...   \n",
       "1  I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
       "\n",
       "                               ticket_classification  \\\n",
       "0                 Debt collection + Credit card debt   \n",
       "1  Credit card or prepaid card + General-purpose ...   \n",
       "\n",
       "                                      processed_text relevant_topics  \n",
       "0  morn name appreci chase bank cardmemb servic c...   Mortgage/Loan  \n",
       "1  card anniversari date inform order account ann...   Mortgage/Loan  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant_topics\n",
       "Mortgage/Loan                    16376\n",
       "Bank Account Services             2358\n",
       "Credit Report or Prepaid Card      227\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"relevant_topics\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = data[\"processed_text\"]\n",
    "y_encoded = data[\"relevant_topics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx2label(json_path: str) -> pd.Series:\n",
    "    \"\"\"This function read the json file and return a dictionary\n",
    "    Args:\n",
    "      json_path (str): path to the json file\n",
    "     Returns:\n",
    "      idx2label (dict): dictionary with the mapping\"\"\"\n",
    "    with open(json_path) as f:\n",
    "        idx2label = json.load(f)\n",
    "    return idx2label\n",
    "\n",
    "idx2label = read_idx2label(json_path=\"../topic_mapping_1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels_into_idx(labels: pd.Series, idx2label: dict) -> pd.Series:\n",
    "    \"\"\"This function decode the labels into idx\n",
    "    Args:\n",
    "      labels (pd.Series): series with the labels\n",
    "      idx2label (dict): dictionary with the mapping\n",
    "     Returns:\n",
    "      labels (pd.Series): series with the labels decoded\n",
    "    \"\"\"\n",
    "    return labels.map(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = {value: key for key, value in idx2label.items()}\n",
    "y = decode_labels_into_idx(labels=y_encoded, idx2label=label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        0\n",
       "4        2\n",
       "        ..\n",
       "18956    2\n",
       "18957    2\n",
       "18958    2\n",
       "18959    2\n",
       "18960    2\n",
       "Name: relevant_topics, Length: 18961, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer =TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "majority_class = y_train.value_counts().idxmax()\n",
    "print(majority_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(constant=&#x27;2&#x27;, strategy=&#x27;constant&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(constant=&#x27;2&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(constant='2', strategy='constant')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_classifer = DummyClassifier(strategy=\"constant\", constant=majority_class)\n",
    "dummy_classifer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jam/anaconda3/envs/mlops/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jam/anaconda3/envs/mlops/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       705\n",
      "           1       0.00      0.00      0.00        79\n",
      "           2       0.86      1.00      0.93      4905\n",
      "\n",
      "    accuracy                           0.86      5689\n",
      "   macro avg       0.29      0.33      0.31      5689\n",
      "weighted avg       0.74      0.86      0.80      5689\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jam/anaconda3/envs/mlops/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "baseline_predictions = dummy_classifer.predict(X_test)\n",
    "print(classification_report(y_test, baseline_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: 2, Cantidad de predicciones: 5689\n"
     ]
    }
   ],
   "source": [
    "unique_classes, counts = np.unique(baseline_predictions, return_counts=True)\n",
    "\n",
    "for label, count in zip(unique_classes, counts):\n",
    "    print(f'Clase: {label}, Cantidad de predicciones: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de predicción muestran una distribución en la que la clase 2 tiene una cantidad significativamente mayor de predicciones en comparación con las otras clases. Mientras tanto, en los datos reales de prueba (y_test), se observa una distribución más equilibrada entre las clases.\n",
    "\n",
    "Esta discrepancia entre las predicciones del modelo baseline y los datos reales subraya la simplicidad del modelo baseline y su incapacidad para capturar la complejidad del problema de clasificación. Es importante tener en cuenta que este modelo simple se usa principalmente como punto de referencia inicial y no refleja el rendimiento real de un modelo de clasificación más sofisticado. En problemas reales, se esperaría que un modelo más avanzado mejore significativamente estos resultados.\n",
    "\n",
    "Si necesitas un modelo más preciso, es recomendable explorar modelos de clasificación más complejos y técnicas de ajuste de hiperparámetros o incluso modelos de aprendizaje profundo, dependiendo de la naturaleza y la complejidad de tus datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26       466\n",
      "           1       0.10      0.22      0.13        54\n",
      "           2       0.89      0.68      0.77      3273\n",
      "\n",
      "    accuracy                           0.64      3793\n",
      "   macro avg       0.39      0.45      0.39      3793\n",
      "weighted avg       0.79      0.64      0.70      3793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear la representación TF-IDF del texto  - da más importancia a palabras con mayor peso\n",
    "from sklearn import svm\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Inicializar y entrenar el modelo SVM\n",
    "svm_classifier = svm.SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba y train \n",
    "predictions_test = svm_classifier.predict(X_test_tfidf)\n",
    "predictions_train = svm_classifier.predict(X_train_tfidf)\n",
    "\n",
    "# Medir la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, predictions_test)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Ver el reporte de clasificación\n",
    "print(classification_report(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: 0, Cantidad de predicciones: 1177\n",
      "Clase: 1, Cantidad de predicciones: 126\n",
      "Clase: 2, Cantidad de predicciones: 2490\n"
     ]
    }
   ],
   "source": [
    "#Contamos la cantidad de etiquetas que resultaron de la predicción\n",
    "\n",
    "unique_classes, counts = np.unique(predictions_test, return_counts=True)\n",
    "\n",
    "for label, count in zip(unique_classes, counts):\n",
    "    print(f'Clase: {label}, Cantidad de predicciones: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant_topics\n",
       "2    3273\n",
       "0     466\n",
       "1      54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# miramos la cantidad verdadera de etiquetas\n",
    "\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de predicción muestran una distribución en la que la clase 2 tiene una cantidad significativamente mayor de predicciones en comparación con las otras clases. Mientras tanto, en los datos reales de prueba (y_test), se observa una distribución más equilibrada entre las clases.\n",
    "\n",
    "Esta discrepancia entre las predicciones del modelo baseline y los datos reales subraya la simplicidad del modelo baseline y su incapacidad para capturar la complejidad del problema de clasificación. Es importante tener en cuenta que este modelo simple se usa principalmente como punto de referencia inicial y no refleja el rendimiento real de un modelo de clasificación más sofisticado. En problemas reales, se esperaría que un modelo más avanzado mejore significativamente estos resultados.\n",
    "\n",
    "Si necesitas un modelo más preciso, es recomendable explorar modelos de clasificación más complejos y técnicas de ajuste de hiperparámetros o incluso modelos de aprendizaje profundo, dependiendo de la naturaleza y la complejidad de tus datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump model and reference data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar set val como referencia en parquet y modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./model/svm.bin', 'wb') as f_out:\n",
    "    dump(svm_classifier, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos un conjunto de entrenamiento a partir de los datos en X_train\n",
    "train_data = pd.DataFrame({\n",
    "    'texto' : X_train,\n",
    "    'label' : y_train,\n",
    "    'features' : X_train_tfidf,\n",
    "    'predictions' : predictions_train\n",
    "})\n",
    "\n",
    "#Para evitar generar una matriz dispersa grandísima debido a que por cada dato se tenga una columna nueva hacemos:\n",
    "#Generamos pesos aleatorios para la suma ponderarda (número de columnas en la matriz dispersa)\n",
    "num_features = train_data['features'].iloc[0].shape[1]\n",
    "weights = np.random.rand(num_features)\n",
    "\n",
    "#Calcular la suma ponderada para cada fila en 'features y agregarla como una nueva columna\n",
    "weighted_sum = train_data['features'].apply(lambda x: np.sum(x.multiply(weights)))\n",
    "train_data['weighted_sum'] = weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>predictions</th>\n",
       "      <th>weighted_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>origin account chase  debtor skill receiv paym...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 187)\\t0.11892319179943166\\n  (0, 1826)\\t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.457271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>call chase refin home cash  told cash chase cr...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 634)\\t0.42756222346968964\\n  (0, 959)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.633191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>shortsal jp chase agent receiv email  state of...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 379)\\t0.21675049976697044\\n  (0, 511)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.986625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13649</th>\n",
       "      <td>issu judgment pertain case number issu sometim...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 165)\\t0.15845502466661301\\n  (0, 187)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.800358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>complaint chase account cfpb mention compani d...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 181)\\t0.11656510770087931\\n  (0, 187)\\t0...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.626539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>worth custom bank relationship year addit year...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 169)\\t0.013724364396594406\\n  (0, 187)\\t...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.768966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>regard person scam fund chase bank account cla...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 165)\\t0.02422225478798329\\n  (0, 181)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.564118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>travel account contact bank sever time cost lo...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 129)\\t0.15688445162376038\\n  (0, 187)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.115874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>letter fr om chase state th credit card intere...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1599)\\t0.2345680430255364\\n  (0, 1826)\\t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.145125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>check account bank fund account bank bank rece...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 187)\\t0.2212255590534488\\n  (0, 241)\\t0....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.946154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15168 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto label  \\\n",
       "7401   origin account chase  debtor skill receiv paym...     2   \n",
       "13797  call chase refin home cash  told cash chase cr...     2   \n",
       "12609  shortsal jp chase agent receiv email  state of...     2   \n",
       "13649  issu judgment pertain case number issu sometim...     2   \n",
       "7664   complaint chase account cfpb mention compani d...     2   \n",
       "...                                                  ...   ...   \n",
       "11284  worth custom bank relationship year addit year...     2   \n",
       "11964  regard person scam fund chase bank account cla...     2   \n",
       "5390   travel account contact bank sever time cost lo...     2   \n",
       "860    letter fr om chase state th credit card intere...     2   \n",
       "15795  check account bank fund account bank bank rece...     2   \n",
       "\n",
       "                                                features predictions  \\\n",
       "7401     (0, 187)\\t0.11892319179943166\\n  (0, 1826)\\t...           2   \n",
       "13797    (0, 634)\\t0.42756222346968964\\n  (0, 959)\\t0...           2   \n",
       "12609    (0, 379)\\t0.21675049976697044\\n  (0, 511)\\t0...           2   \n",
       "13649    (0, 165)\\t0.15845502466661301\\n  (0, 187)\\t0...           2   \n",
       "7664     (0, 181)\\t0.11656510770087931\\n  (0, 187)\\t0...           0   \n",
       "...                                                  ...         ...   \n",
       "11284    (0, 169)\\t0.013724364396594406\\n  (0, 187)\\t...           0   \n",
       "11964    (0, 165)\\t0.02422225478798329\\n  (0, 181)\\t0...           2   \n",
       "5390     (0, 129)\\t0.15688445162376038\\n  (0, 187)\\t0...           2   \n",
       "860      (0, 1599)\\t0.2345680430255364\\n  (0, 1826)\\t...           2   \n",
       "15795    (0, 187)\\t0.2212255590534488\\n  (0, 241)\\t0....           2   \n",
       "\n",
       "       weighted_sum  \n",
       "7401       1.457271  \n",
       "13797      2.633191  \n",
       "12609      1.986625  \n",
       "13649      3.800358  \n",
       "7664       2.626539  \n",
       "...             ...  \n",
       "11284      5.768966  \n",
       "11964      5.564118  \n",
       "5390       3.115874  \n",
       "860        1.145125  \n",
       "15795      1.946154  \n",
       "\n",
       "[15168 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conjunto de entrenamiento\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos un conjunto de entrenamiento a partir de los datos en X_test\n",
    "test_data = pd.DataFrame({\n",
    "    'texto' : X_test,\n",
    "    'label' : y_test,\n",
    "    'features' : X_test_tfidf,\n",
    "    'predictions' : predictions_test\n",
    "})\n",
    "\n",
    "#Para evitar generar una matriz dispersa grandísima debido a que por cada dato se tenga una columna nueva hacemos:\n",
    "#Generamos pesos aleatorios para la suma ponderarda (número de columnas en la matriz dispersa)\n",
    "num_features = test_data['features'].iloc[0].shape[1]\n",
    "weights = np.random.rand(num_features)\n",
    "\n",
    "#Calcular la suma ponderada para cada fila en 'features y agregarla como una nueva columna\n",
    "weighted_sum = test_data['features'].apply(lambda x: np.sum(x.multiply(weights)))\n",
    "test_data['weighted_sum'] = weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>predictions</th>\n",
       "      <th>weighted_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10644</th>\n",
       "      <td>mail jpchase research department/archives/prop...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 261)\\t0.08169304670272645\\n  (0, 511)\\t0...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.650980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17303</th>\n",
       "      <td>fee refund refin attempt bank zip code.th fee ...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 803)\\t0.10596872378972176\\n  (0, 943)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.688520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>car drunk driver park middl night insur compan...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 187)\\t0.028881131580168303\\n  (0, 511)\\t...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.305398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16341</th>\n",
       "      <td>2018 ct card servic supervisor telephon center...</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 47)\\t0.2687892916887694\\n  (0, 324)\\t0.1...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.027004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14016</th>\n",
       "      <td>car total co ck bank need process gap claim wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 241)\\t0.2963011233165569\\n  (0, 959)\\t0....</td>\n",
       "      <td>2</td>\n",
       "      <td>2.261423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7687</th>\n",
       "      <td>fyi forc chang fix issu compani credit card em...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 187)\\t0.03555354721199063\\n  (0, 247)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.900336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9361</th>\n",
       "      <td>bank account yield account bank husband proces...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 169)\\t0.09092833400303228\\n  (0, 187)\\t0...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.623816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18397</th>\n",
       "      <td>year histori credit score  work hour week mont...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 187)\\t0.09121649576362557\\n  (0, 273)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>year stop call</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1537)\\t0.37867560654113414\\n  (0, 10271)...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.014344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>file disput regard item credit report day result</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 2614)\\t0.20462130394097505\\n  (0, 2815)\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.105136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3793 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto label  \\\n",
       "10644  mail jpchase research department/archives/prop...     2   \n",
       "17303  fee refund refin attempt bank zip code.th fee ...     2   \n",
       "8250   car drunk driver park middl night insur compan...     2   \n",
       "16341  2018 ct card servic supervisor telephon center...     0   \n",
       "14016  car total co ck bank need process gap claim wa...     0   \n",
       "...                                                  ...   ...   \n",
       "7687   fyi forc chang fix issu compani credit card em...     2   \n",
       "9361   bank account yield account bank husband proces...     2   \n",
       "18397  year histori credit score  work hour week mont...     2   \n",
       "4132                                      year stop call     2   \n",
       "3974    file disput regard item credit report day result     2   \n",
       "\n",
       "                                                features predictions  \\\n",
       "10644    (0, 261)\\t0.08169304670272645\\n  (0, 511)\\t0...           0   \n",
       "17303    (0, 803)\\t0.10596872378972176\\n  (0, 943)\\t0...           2   \n",
       "8250     (0, 187)\\t0.028881131580168303\\n  (0, 511)\\t...           2   \n",
       "16341    (0, 47)\\t0.2687892916887694\\n  (0, 324)\\t0.1...           0   \n",
       "14016    (0, 241)\\t0.2963011233165569\\n  (0, 959)\\t0....           2   \n",
       "...                                                  ...         ...   \n",
       "7687     (0, 187)\\t0.03555354721199063\\n  (0, 247)\\t0...           2   \n",
       "9361     (0, 169)\\t0.09092833400303228\\n  (0, 187)\\t0...           0   \n",
       "18397    (0, 187)\\t0.09121649576362557\\n  (0, 273)\\t0...           2   \n",
       "4132     (0, 1537)\\t0.37867560654113414\\n  (0, 10271)...           2   \n",
       "3974     (0, 2614)\\t0.20462130394097505\\n  (0, 2815)\\...           0   \n",
       "\n",
       "       weighted_sum  \n",
       "10644      2.650980  \n",
       "17303      2.688520  \n",
       "8250       2.305398  \n",
       "16341      2.027004  \n",
       "14016      2.261423  \n",
       "...             ...  \n",
       "7687       2.900336  \n",
       "9361       2.623816  \n",
       "18397      3.981047  \n",
       "4132       1.014344  \n",
       "3974       1.105136  \n",
       "\n",
       "[3793 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import ColumnDriftMetric, DatasetDriftMetric, DatasetMissingValuesMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacemos unas tranformaciones para que la librería evidently tenga los valores correctamente con su tipado\n",
    "test_data[\"label\"] = test_data[\"label\"].astype(int)\n",
    "train_data[\"label\"] = train_data[\"label\"].astype(int)\n",
    "\n",
    "#aseguramos que las predicciones sean int y no object\n",
    "test_data[\"predictions\"] = test_data[\"predictions\"].astype(int)\n",
    "train_data[\"predictions\"] = train_data[\"predictions\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>predictions</th>\n",
       "      <th>weighted_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>origin account chase  debtor skill receiv paym...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 187)\\t0.11892319179943166\\n  (0, 1826)\\t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.457271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>call chase refin home cash  told cash chase cr...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 634)\\t0.42756222346968964\\n  (0, 959)\\t0...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.633191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto  label  \\\n",
       "7401   origin account chase  debtor skill receiv paym...      2   \n",
       "13797  call chase refin home cash  told cash chase cr...      2   \n",
       "\n",
       "                                                features  predictions  \\\n",
       "7401     (0, 187)\\t0.11892319179943166\\n  (0, 1826)\\t...            2   \n",
       "13797    (0, 634)\\t0.42756222346968964\\n  (0, 959)\\t0...            2   \n",
       "\n",
       "       weighted_sum  \n",
       "7401       1.457271  \n",
       "13797      2.633191  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformamos la parte de las features\n",
    "#la columnas features es de tipo object, necesitamos que sea un toarray\n",
    "#es decir indicarle que esa columna es verdaderamente una matriz dispersa\n",
    "#generamos columna nueva\n",
    "\n",
    "test_data[\"features_dense\"] = test_data[\"features\"].apply(lambda x: x.toarray())\n",
    "train_data[\"features_dense\"] = train_data[\"features\"].apply(lambda x: x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>predictions</th>\n",
       "      <th>weighted_sum</th>\n",
       "      <th>features_dense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>appli approv amazon reward visa card color iss...</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 187)\\t0.1261376544233375\\n  (0, 494)\\t0....</td>\n",
       "      <td>2</td>\n",
       "      <td>2.701884</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>2019 deposit check jp chase texa payrol check ...</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 49)\\t0.09448444566740115\\n  (0, 187)\\t0....</td>\n",
       "      <td>0</td>\n",
       "      <td>3.002906</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto  label  \\\n",
       "3645  appli approv amazon reward visa card color iss...      2   \n",
       "5182  2019 deposit check jp chase texa payrol check ...      0   \n",
       "\n",
       "                                               features  predictions  \\\n",
       "3645    (0, 187)\\t0.1261376544233375\\n  (0, 494)\\t0....            2   \n",
       "5182    (0, 49)\\t0.09448444566740115\\n  (0, 187)\\t0....            0   \n",
       "\n",
       "      weighted_sum                                     features_dense  \n",
       "3645      2.701884  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "5182      3.002906  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Revisamos que se haya hecho la transformación\n",
    "train_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hay algunas columnas que no son necesarias para evidently \n",
    "#todo lo que se va a anlaizar por evidently debe estar en formato hasheable\n",
    "#Es decir que se puedar iterar\n",
    "#Vamos a hacer una agrupación, dado test y train solamente contengan las columnas bajo el formato evidently\n",
    "\n",
    "test_data = test_data[[\"label\", \"predictions\", \"weighted_sum\"]]\n",
    "train_data = train_data[[\"label\", \"predictions\", \"weighted_sum\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predictions</th>\n",
       "      <th>weighted_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.716825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.047902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  predictions  weighted_sum\n",
       "8028      2            2      1.716825\n",
       "7171      2            2      2.047902"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
